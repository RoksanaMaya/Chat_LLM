{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langchain.chains (from versions: none)\n",
      "ERROR: No matching distribution found for langchain.chains\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain.chains \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "#from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the chatbot! Type 'exit' to end the conversation.\n",
      "Assistant: I'm doing well, thanks for asking! It's great to be chatting with you. What brings you here today?\n",
      "Assistant: I'd be happy to help!\n",
      "\n",
      "As of my knowledge cutoff, Bangladesh follows the Gregorian calendar. So, I'll provide you with the current date in Bangladesh.\n",
      "\n",
      "Please note that the Bangladeshi calendar is 593 years behind the Gregorian calendar due to a difference in the starting dates. For simplicity, we'll use the Gregorian calendar for our purpose.\n",
      "\n",
      "To get the exact date in BD, please let me know which year or month you're interested in.\n",
      "Assistant: Let's get straight to it. I'm ready when you are. What's on your mind?\n",
      "Assistant: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Template\n",
    "template = \"\"\"\n",
    "\n",
    "User: {question}\n",
    "\n",
    "Assistant: Let's answer to the point.\n",
    "\"\"\"\n",
    "# prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "# Create the chain\n",
    "#chain = LLMChain(prompt=prompt, llm=model)\n",
    "chain = prompt | model\n",
    "\n",
    "def chat():\n",
    "    print(\"Welcome to the chatbot! Type 'exit' to end the conversation.\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Assistant: Goodbye!\")\n",
    "            break\n",
    "        response = chain.invoke({\"question\": user_input})\n",
    "        print(f\"Assistant: {response}\")\n",
    "\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
